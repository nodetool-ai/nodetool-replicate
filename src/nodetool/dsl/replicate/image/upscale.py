# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class ClarityUpscaler(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    High resolution image Upscaler and Enhancer. Use at ClarityAI.co. A free Magnific alternative. Twitter/X: @philz1337x
    """

    Handfix: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Handfix
    )
    Sd_model: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Sd_model
    )
    Scheduler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Scheduler
    )
    Tiling_width: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_width
    )
    Output_format: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Output_format
    )
    Tiling_height: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_height
    )

    mask: str | OutputHandle[str] | None = connect_field(
        default=None,
        description="Mask image to mark areas that should be preserved during upscaling",
    )
    seed: int | OutputHandle[int] = connect_field(
        default=1337, description="Random seed. Leave blank to randomize the seed"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="input image",
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="masterpiece, best quality, highres, <lora:more_details:0.5> <lora:SDXLrender_v2.0:1>",
        description="Prompt",
    )
    dynamic: float | OutputHandle[float] = connect_field(
        default=6, description="HDR, try from 3 - 9"
    )
    handfix: nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Handfix = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Handfix(
            "disabled"
        ),
        description="Use clarity to fix hands in the image",
    )
    pattern: bool | OutputHandle[bool] = connect_field(
        default=False, description="Upscale a pattern with seamless tiling"
    )
    sharpen: float | OutputHandle[float] = connect_field(
        default=0,
        description="Sharpen the image after upscaling. The higher the value, the more sharpening is applied. 0 for no sharpening",
    )
    sd_model: nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Sd_model = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Sd_model(
            "juggernaut_reborn.safetensors [338b85bc4f]"
        ),
        description="Stable Diffusion model checkpoint",
    )
    scheduler: nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Scheduler = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Scheduler(
            "DPM++ 3M SDE Karras"
        ),
        description="scheduler",
    )
    creativity: float | OutputHandle[float] = connect_field(
        default=0.35, description="Creativity, try from 0.3 - 0.9"
    )
    lora_links: str | OutputHandle[str] = connect_field(
        default="",
        description="Link to a lora file you want to use in your upscaling. Multiple links possible, seperated by comma",
    )
    downscaling: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="Downscale the image before upscaling. Can improve quality and speed for images with high resolution but lower quality",
    )
    resemblance: float | OutputHandle[float] = connect_field(
        default=0.6, description="Resemblance, try from 0.3 - 1.6"
    )
    scale_factor: float | OutputHandle[float] = connect_field(
        default=2, description="Scale factor"
    )
    tiling_width: (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_width
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_width(
            112
        ),
        description="Fractality, set lower tile width for a high Fractality",
    )
    output_format: (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Output_format
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Output_format(
            "png"
        ),
        description="Format of the output images",
    )
    tiling_height: (
        nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_height
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.ClarityUpscaler.Tiling_height(
            144
        ),
        description="Fractality, set lower tile height for a high Fractality",
    )
    custom_sd_model: str | OutputHandle[str] = connect_field(
        default="", description=None
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="(worst quality, low quality, normal quality:2) JuggernautNegative-neg",
        description="Negative Prompt",
    )
    num_inference_steps: int | OutputHandle[int] = connect_field(
        default=18, description="Number of denoising steps"
    )
    downscaling_resolution: int | OutputHandle[int] = connect_field(
        default=768, description="Downscaling resolution"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.ClarityUpscaler

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class GFPGAN(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Practical face restoration algorithm for *old photos* or *AI-generated faces*
    """

    Version: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.GFPGAN.Version
    )

    img: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input",
    )
    scale: float | OutputHandle[float] = connect_field(
        default=2, description="Rescaling factor"
    )
    version: nodetool.nodes.replicate.image.upscale.GFPGAN.Version = Field(
        default=nodetool.nodes.replicate.image.upscale.GFPGAN.Version("v1.4"),
        description="GFPGAN version. v1.3: better quality. v1.4: more details and better identity.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.GFPGAN

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class HighResolutionControlNetTile(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    UPDATE: new upscaling algorithm for a much improved image quality. Fermat.app open-source implementation of an efficient ControlNet 1.1 tile for high-quality upscales. Increase the creativity to encourage hallucination.
    """

    Format: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Format
    )
    Scheduler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Scheduler
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Resolution
    )

    hdr: float | OutputHandle[float] = connect_field(
        default=0, description="HDR improvement over the original image"
    )
    seed: int | OutputHandle[int] | None = connect_field(
        default=None, description="Seed"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Control image for scribble controlnet",
    )
    steps: int | OutputHandle[int] = connect_field(default=8, description="Steps")
    format: (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Format
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Format(
            "jpg"
        ),
        description="Format of the output.",
    )
    prompt: str | OutputHandle[str] | None = connect_field(
        default=None, description="Prompt for the model"
    )
    scheduler: (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Scheduler
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Scheduler(
            "DDIM"
        ),
        description="Choose a scheduler.",
    )
    creativity: float | OutputHandle[float] = connect_field(
        default=0.35,
        description="Denoising strength. 1 means total destruction of the original image",
    )
    guess_mode: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="In this mode, the ControlNet encoder will try best to recognize the content of the input image even if you remove all prompts.",
    )
    resolution: (
        nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Resolution
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile.Resolution(
            2560
        ),
        description="Image resolution",
    )
    resemblance: float | OutputHandle[float] = connect_field(
        default=0.85, description="Conditioning scale for controlnet"
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=0, description="Scale for classifier-free guidance, should be 0."
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="teeth, tooth, open mouth, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, mutant",
        description="Negative prompt",
    )
    lora_details_strength: float | OutputHandle[float] = connect_field(
        default=1, description="Strength of the image's details"
    )
    lora_sharpness_strength: float | OutputHandle[float] = connect_field(
        default=1.25,
        description="Strength of the image's sharpness. We don't recommend values above 2.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.HighResolutionControlNetTile

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class MagicImageRefiner(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    A better alternative to SDXL refiners, providing a lot of quality and detail. Can also be used for inpainting or upscaling.
    """

    Scheduler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Scheduler
    )
    Resolution: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Resolution
    )

    hdr: float | OutputHandle[float] = connect_field(
        default=0, description="HDR improvement over the original image"
    )
    mask: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="When provided, refines some section of the image. Must be the same size as the image",
    )
    seed: int | OutputHandle[int] | None = connect_field(
        default=None, description="Seed"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Image to refine",
    )
    steps: int | OutputHandle[int] = connect_field(default=20, description="Steps")
    prompt: str | OutputHandle[str] | None = connect_field(
        default=None, description="Prompt for the model"
    )
    scheduler: nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Scheduler = (
        Field(
            default=nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Scheduler(
                "DDIM"
            ),
            description="Choose a scheduler.",
        )
    )
    creativity: float | OutputHandle[float] = connect_field(
        default=0.25,
        description="Denoising strength. 1 means total destruction of the original image",
    )
    guess_mode: bool | OutputHandle[bool] = connect_field(
        default=False,
        description="In this mode, the ControlNet encoder will try best to recognize the content of the input image even if you remove all prompts. The `guidance_scale` between 3.0 and 5.0 is recommended.",
    )
    resolution: nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Resolution = (
        Field(
            default=nodetool.nodes.replicate.image.upscale.MagicImageRefiner.Resolution(
                "original"
            ),
            description="Image resolution",
        )
    )
    resemblance: float | OutputHandle[float] = connect_field(
        default=0.75, description="Conditioning scale for controlnet"
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=7, description="Scale for classifier-free guidance"
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="teeth, tooth, open mouth, longbody, lowres, bad anatomy, bad hands, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, mutant",
        description="Negative prompt",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.MagicImageRefiner

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class RealEsrGan(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Real-ESRGAN for image upscaling on an A100
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )
    scale: float | OutputHandle[float] = connect_field(
        default=4, description="Factor to scale image by"
    )
    face_enhance: bool | OutputHandle[bool] = connect_field(
        default=False, description="Run GFPGAN face enhancement along with upscaling"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.RealEsrGan

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class Swin2SR(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    3 Million Runs! AI Photorealistic Image Super-Resolution and Restoration
    """

    Task: typing.ClassVar[type] = nodetool.nodes.replicate.image.upscale.Swin2SR.Task

    task: nodetool.nodes.replicate.image.upscale.Swin2SR.Task = Field(
        default=nodetool.nodes.replicate.image.upscale.Swin2SR.Task("real_sr"),
        description="Choose a task",
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.Swin2SR

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class SwinIR(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Image Restoration Using Swin Transformer
    """

    Noise: typing.ClassVar[type] = nodetool.nodes.replicate.image.upscale.SwinIR.Noise
    Task_type: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.SwinIR.Task_type
    )

    jpeg: int | OutputHandle[int] = connect_field(
        default=40,
        description="scale factor, activated for JPEG Compression Artifact Reduction. Leave it as default or arbitrary if other tasks are selected",
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="input image",
    )
    noise: nodetool.nodes.replicate.image.upscale.SwinIR.Noise = Field(
        default=nodetool.nodes.replicate.image.upscale.SwinIR.Noise(15),
        description="noise level, activated for Grayscale Image Denoising and Color Image Denoising. Leave it as default or arbitrary if other tasks are selected",
    )
    task_type: nodetool.nodes.replicate.image.upscale.SwinIR.Task_type = Field(
        default=nodetool.nodes.replicate.image.upscale.SwinIR.Task_type(
            "Real-World Image Super-Resolution-Large"
        ),
        description="Choose a task",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.SwinIR

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class UltimateSDUpscale(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Ultimate SD Upscale with ControlNet Tile
    """

    Upscaler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Upscaler
    )
    Mode_type: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Mode_type
    )
    Scheduler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Scheduler
    )
    Sampler_name: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Sampler_name
    )
    Seam_fix_mode: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Seam_fix_mode
    )

    cfg: float | OutputHandle[float] = connect_field(default=8, description="CFG")
    seed: int | OutputHandle[int] | None = connect_field(
        default=None, description="Sampling seed, leave Empty for Random"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )
    steps: int | OutputHandle[int] = connect_field(default=20, description="Steps")
    denoise: float | OutputHandle[float] = connect_field(
        default=0.2, description="Denoise"
    )
    upscaler: nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Upscaler = Field(
        default=nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Upscaler(
            "4x-UltraSharp"
        ),
        description="Upscaler",
    )
    mask_blur: int | OutputHandle[int] = connect_field(
        default=8, description="Mask Blur"
    )
    mode_type: nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Mode_type = (
        Field(
            default=nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Mode_type(
                "Linear"
            ),
            description="Mode Type",
        )
    )
    scheduler: nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Scheduler = (
        Field(
            default=nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Scheduler(
                "normal"
            ),
            description="Scheduler",
        )
    )
    tile_width: int | OutputHandle[int] = connect_field(
        default=512, description="Tile Width"
    )
    upscale_by: float | OutputHandle[float] = connect_field(
        default=2, description="Upscale By"
    )
    tile_height: int | OutputHandle[int] = connect_field(
        default=512, description="Tile Height"
    )
    sampler_name: (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Sampler_name
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Sampler_name(
            "euler"
        ),
        description="Sampler",
    )
    tile_padding: int | OutputHandle[int] = connect_field(
        default=32, description="Tile Padding"
    )
    seam_fix_mode: (
        nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Seam_fix_mode
    ) = Field(
        default=nodetool.nodes.replicate.image.upscale.UltimateSDUpscale.Seam_fix_mode(
            "None"
        ),
        description="Seam Fix Mode",
    )
    seam_fix_width: int | OutputHandle[int] = connect_field(
        default=64, description="Seam Fix Width"
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Negative Prompt"
    )
    positive_prompt: str | OutputHandle[str] = connect_field(
        default="Hey! Have a nice day :D", description="Positive Prompt"
    )
    seam_fix_denoise: float | OutputHandle[float] = connect_field(
        default=1, description="Seam Fix Denoise"
    )
    seam_fix_padding: int | OutputHandle[int] = connect_field(
        default=16, description="Seam Fix Padding"
    )
    seam_fix_mask_blur: int | OutputHandle[int] = connect_field(
        default=8, description="Seam Fix Mask Blur"
    )
    controlnet_strength: float | OutputHandle[float] = connect_field(
        default=1, description="ControlNet Strength"
    )
    force_uniform_tiles: bool | OutputHandle[bool] = connect_field(
        default=True, description="Force Uniform Tiles"
    )
    use_controlnet_tile: bool | OutputHandle[bool] = connect_field(
        default=True, description="Use ControlNet Tile"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.UltimateSDUpscale

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.upscale
from nodetool.workflows.base_node import BaseNode


class ruDallE_SR(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Real-ESRGAN super-resolution model from ruDALL-E
    """

    Scale: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.upscale.ruDallE_SR.Scale
    )

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )
    scale: nodetool.nodes.replicate.image.upscale.ruDallE_SR.Scale = Field(
        default=nodetool.nodes.replicate.image.upscale.ruDallE_SR.Scale(4),
        description="Choose up-scaling factor",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.upscale.ruDallE_SR

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
