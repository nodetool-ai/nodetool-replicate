# This file is auto-generated by nodetool.dsl.codegen.
# Please do not edit this file manually.

# Instead, edit the node class in the source module and run the following commands to regenerate the DSL:
# nodetool package scan
# nodetool codegen

from pydantic import BaseModel, Field
import typing
from typing import Any
import nodetool.metadata.types
import nodetool.metadata.types as types
from nodetool.dsl.graph import GraphNode, SingleOutputGraphNode

import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class DD_Color(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Towards Photo-Realistic Image Colorization via Dual Decoders
    """

    Model_size: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.process.DD_Color.Model_size
    )

    image: str | OutputHandle[str] | None = connect_field(
        default=None, description="Grayscale input image."
    )
    model_size: nodetool.nodes.replicate.image.process.DD_Color.Model_size = Field(
        default=nodetool.nodes.replicate.image.process.DD_Color.Model_size("large"),
        description="Choose the model size.",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.DD_Color

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class Expand_Image(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Bria Expand expands images beyond their borders in high quality. Resizing the image by generating new pixels to expand to the desired aspect ratio. Trained exclusively on licensed data for safe and risk-free commercial use
    """

    Aspect_ratio: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.process.Expand_Image.Aspect_ratio
    )

    seed: int | OutputHandle[int] | None = connect_field(
        default=None, description="Random seed. Set for reproducible generation"
    )
    sync: bool | OutputHandle[bool] = connect_field(
        default=True, description="Synchronous response mode"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Image file",
    )
    prompt: str | OutputHandle[str] | None = connect_field(
        default=None, description="Text prompt for image generation"
    )
    image_url: str | OutputHandle[str] | None = connect_field(
        default=None, description="Image URL"
    )
    canvas_size: list | OutputHandle[list] | None = connect_field(
        default=None,
        description="Desired output canvas dimensions [width, height]. Default [1000, 1000]. Max 5000x5000 pixels.",
    )
    aspect_ratio: nodetool.nodes.replicate.image.process.Expand_Image.Aspect_ratio = (
        Field(
            default=nodetool.nodes.replicate.image.process.Expand_Image.Aspect_ratio(
                "1:1"
            ),
            description="Aspect ratio for expansion. Either aspect_ratio or canvas_size with original_image_size/location must be provided. Can be a predefined string like '1:1', '16:9' etc. or a custom float between 0.5 and 3.0",
        )
    )
    preserve_alpha: bool | OutputHandle[bool] = connect_field(
        default=True,
        description="Preserve alpha channel in output. When true, maintains original transparency. When false, output is fully opaque.",
    )
    negative_prompt: str | OutputHandle[str] | None = connect_field(
        default=None, description="Negative prompt for image generation"
    )
    content_moderation: bool | OutputHandle[bool] = connect_field(
        default=False, description="Enable content moderation"
    )
    original_image_size: list | OutputHandle[list] | None = connect_field(
        default=None, description="Size of original image in canvas [width, height]"
    )
    original_image_location: list | OutputHandle[list] | None = connect_field(
        default=None, description="Position of original image in canvas [x, y]"
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.Expand_Image

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class Magic_Style_Transfer(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Restyle an image with the style of another one. I strongly suggest to upscale the results with Clarity AI
    """

    Scheduler: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.process.Magic_Style_Transfer.Scheduler
    )

    seed: int | OutputHandle[int] | None = connect_field(
        default=None, description="Random seed. Leave blank to randomize the seed"
    )
    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )
    prompt: str | OutputHandle[str] = connect_field(
        default="An astronaut riding a rainbow unicorn", description="Input prompt"
    )
    ip_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image for img2img or inpaint mode",
    )
    ip_scale: float | OutputHandle[float] = connect_field(
        default=0.3, description="IP Adapter strength."
    )
    strength: float | OutputHandle[float] = connect_field(
        default=0.9,
        description="When img2img is active, the denoising strength. 1 means total destruction of the input image.",
    )
    scheduler: nodetool.nodes.replicate.image.process.Magic_Style_Transfer.Scheduler = (
        Field(
            default=nodetool.nodes.replicate.image.process.Magic_Style_Transfer.Scheduler(
                "K_EULER"
            ),
            description="scheduler",
        )
    )
    lora_scale: float | OutputHandle[float] = connect_field(
        default=0.9,
        description="LoRA additive scale. Only applicable on trained models.",
    )
    num_outputs: int | OutputHandle[int] = connect_field(
        default=1, description="Number of images to output"
    )
    lora_weights: str | OutputHandle[str] | None = connect_field(
        default=None,
        description="Replicate LoRA weights to use. Leave blank to use the default weights.",
    )
    guidance_scale: float | OutputHandle[float] = connect_field(
        default=4, description="Scale for classifier-free guidance"
    )
    resizing_scale: float | OutputHandle[float] = connect_field(
        default=1,
        description="If you want the image to have a solid margin. Scale of the solid margin. 1.0 means no resizing.",
    )
    apply_watermark: bool | OutputHandle[bool] = connect_field(
        default=True,
        description="Applies a watermark to enable determining if an image is generated in downstream applications. If you have other provisions for generating or deploying images safely, you can use this to disable watermarking.",
    )
    negative_prompt: str | OutputHandle[str] = connect_field(
        default="", description="Input Negative Prompt"
    )
    background_color: str | OutputHandle[str] = connect_field(
        default="#A2A2A2",
        description="When passing an image with alpha channel, it will be replaced with this color",
    )
    num_inference_steps: int | OutputHandle[int] = connect_field(
        default=30, description="Number of denoising steps"
    )
    condition_canny_scale: float | OutputHandle[float] = connect_field(
        default=0.15,
        description="The bigger this number is, the more ControlNet interferes",
    )
    condition_depth_scale: float | OutputHandle[float] = connect_field(
        default=0.35,
        description="The bigger this number is, the more ControlNet interferes",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.Magic_Style_Transfer

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class ModNet(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    A deep learning approach to remove background & adding new background image
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="input image",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.ModNet

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class Nano_Banana(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    Google's latest image editing model in Gemini 2.5
    """

    Aspect_ratio: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.process.Nano_Banana.Aspect_ratio
    )
    Output_format: typing.ClassVar[type] = (
        nodetool.nodes.replicate.image.process.Nano_Banana.Output_format
    )

    prompt: str | OutputHandle[str] | None = connect_field(
        default=None, description="A text description of the image you want to generate"
    )
    image_input: list | OutputHandle[list] = connect_field(
        default=[],
        description="Input images to transform or use as reference (supports multiple images)",
    )
    aspect_ratio: nodetool.nodes.replicate.image.process.Nano_Banana.Aspect_ratio = (
        Field(
            default=nodetool.nodes.replicate.image.process.Nano_Banana.Aspect_ratio(
                "match_input_image"
            ),
            description="Aspect ratio of the generated image",
        )
    )
    output_format: nodetool.nodes.replicate.image.process.Nano_Banana.Output_format = (
        Field(
            default=nodetool.nodes.replicate.image.process.Nano_Banana.Output_format(
                "jpg"
            ),
            description="Format of the output image",
        )
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.Nano_Banana

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class ObjectRemover(SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]):
    """
    None
    """

    org_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Original input image",
    )
    mask_image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Mask image",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.ObjectRemover

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()


import typing
from pydantic import Field
from nodetool.dsl.handles import OutputHandle, OutputsProxy, connect_field
import nodetool.nodes.replicate.image.process
from nodetool.workflows.base_node import BaseNode


class RemoveBackground(
    SingleOutputGraphNode[types.ImageRef], GraphNode[types.ImageRef]
):
    """
    Remove images background
    """

    image: types.ImageRef | OutputHandle[types.ImageRef] = connect_field(
        default=types.ImageRef(
            type="image", uri="", asset_id=None, data=None, metadata=None
        ),
        description="Input image",
    )

    @classmethod
    def get_node_class(cls) -> type[BaseNode]:
        return nodetool.nodes.replicate.image.process.RemoveBackground

    @classmethod
    def get_node_type(cls):
        return cls.get_node_class().get_node_type()
